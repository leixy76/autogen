"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[4596],{15399:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>r,contentTitle:()=>i,default:()=>g,frontMatter:()=>s,metadata:()=>u,toc:()=>h});var o=t(85893),a=t(11151);const s={custom_edit_url:"https://github.com/microsoft/autogen/edit/main/website/docs/tutorial/human-in-the-loop.ipynb",source_notebook:"/website/docs/tutorial/human-in-the-loop.ipynb",title:"Allowing Human Feedback in Agents"},i="Allowing Human Feedback in Agents",u={id:"tutorial/human-in-the-loop",title:"Allowing Human Feedback in Agents",description:"Open In Colab",source:"@site/docs/tutorial/human-in-the-loop.mdx",sourceDirName:"tutorial",slug:"/tutorial/human-in-the-loop",permalink:"/autogen/docs/tutorial/human-in-the-loop",draft:!1,unlisted:!1,editUrl:"https://github.com/microsoft/autogen/edit/main/website/docs/tutorial/human-in-the-loop.ipynb",tags:[],version:"current",frontMatter:{custom_edit_url:"https://github.com/microsoft/autogen/edit/main/website/docs/tutorial/human-in-the-loop.ipynb",source_notebook:"/website/docs/tutorial/human-in-the-loop.ipynb",title:"Allowing Human Feedback in Agents"},sidebar:"docsSidebar",previous:{title:"Terminating Conversations Between Agents",permalink:"/autogen/docs/tutorial/termination"},next:{title:"Code Executors",permalink:"/autogen/docs/tutorial/code-executors"}},r={},h=[{value:"Human Input Modes",id:"human-input-modes",level:2},{value:"Human Input Mode = <code>NEVER</code>",id:"human-input-mode-never",level:2},{value:"Human Input Mode = <code>ALWAYS</code>",id:"human-input-mode-always",level:2},{value:"Human Input Mode = <code>TERMINATE</code>",id:"human-input-mode-terminate",level:2},{value:"Summary",id:"summary",level:2}];function m(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,a.a)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.h1,{id:"allowing-human-feedback-in-agents",children:"Allowing Human Feedback in Agents"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.a,{href:"https://colab.research.google.com/github/microsoft/autogen/blob/main/website/docs/tutorial/human-in-the-loop.ipynb",children:(0,o.jsx)(e.img,{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"})}),"\n",(0,o.jsx)(e.a,{href:"https://github.com/microsoft/autogen/blob/main/website/docs/tutorial/human-in-the-loop.ipynb",children:(0,o.jsx)(e.img,{src:"https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github",alt:"Open on GitHub"})})]}),"\n",(0,o.jsxs)(e.p,{children:["In the last two chapters we introduced the ",(0,o.jsx)(e.code,{children:"ConversableAgent"})," class and\nshowed how you can use it to create autonomous\n(",(0,o.jsx)(e.code,{children:"human_input_mode=NEVER"}),") agents that can accomplish tasks. We also\nshowed how to properly terminate a conversation between agents."]}),"\n",(0,o.jsx)(e.p,{children:"But many applications may require putting humans in-the-loop with\nagents. For example, to allow human feedback to steer agents in the\nright direction, specify goals, etc. In this chapter, we will show how\nAutoGen supports human intervention."}),"\n",(0,o.jsx)(e.h2,{id:"human-input-modes",children:"Human Input Modes"}),"\n",(0,o.jsxs)(e.p,{children:["Currently AutoGen supports three modes for human input. The mode is\nspecified through the ",(0,o.jsx)(e.code,{children:"human_input_mode"})," argument of the\n",(0,o.jsx)(e.code,{children:"ConversableAgent"}),". The three modes are:"]}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"NEVER"}),": human input is never requested."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"TERMINATE"})," (default): human input is only requested when a\ntermination condition is met. Note that in this mode if the human\nchooses to intercept and reply, the conversation continues and the\ncounter used by ",(0,o.jsx)(e.code,{children:"max_consectuive_auto_reply"})," is reset."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"ALWAYS"}),": human input is always requested and the human can choose\nto skip and trigger an auto-reply, intercept and provide feedback,\nor terminate the conversation. Note that in this mode termination\nbased on ",(0,o.jsx)(e.code,{children:"max_consecutive_auto_reply"})," is ignored."]}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:["The previous chapters already showed many examples of the cases when\n",(0,o.jsx)(e.code,{children:"human_input_mode"})," is ",(0,o.jsx)(e.code,{children:"NEVER"}),". Below we show one such example again and\nthen show the differences when this mode is set to ",(0,o.jsx)(e.code,{children:"ALWAYS"})," and ",(0,o.jsx)(e.code,{children:"NEVER"}),"\ninstead."]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import os\nfrom autogen import ConversableAgent\n"})}),"\n",(0,o.jsxs)(e.h2,{id:"human-input-mode-never",children:["Human Input Mode = ",(0,o.jsx)(e.code,{children:"NEVER"})]}),"\n",(0,o.jsx)(e.p,{children:"In this mode, human input is never requested and the termination\nconditions are used to terminate. This mode is useful when you want your\nagents to act fully autonomously."}),"\n",(0,o.jsxs)(e.p,{children:["Here is an example of using this mode to run a simple guess-a-number\ngame between two agents, with the maximum number of guesses set to 5\nthrough ",(0,o.jsx)(e.code,{children:"max_consecutive_auto_reply"}),", and the termination message set to\ncheck for the number that is the correct guess."]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'agent_with_number = ConversableAgent(\n    "agent_with_number",\n    system_message="You are playing a game of guess-my-number. You have the "\n    "number 53 in your mind, and I will try to guess it. "\n    "If I guess too high, say \'too high\', if I guess too low, say \'too low\'. ",\n    llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},\n    is_termination_msg=lambda msg: "53" in msg["content"],  # terminate if the number is guessed by the other agent\n    human_input_mode="NEVER",  # never ask for human input\n)\n\nagent_guess_number = ConversableAgent(\n    "agent_guess_number",\n    system_message="I have a number in my mind, and you will try to guess it. "\n    "If I say \'too high\', you should guess a lower number. If I say \'too low\', "\n    "you should guess a higher number. ",\n    llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},\n    human_input_mode="NEVER",\n)\n\nresult = agent_with_number.initiate_chat(\n    agent_guess_number,\n    message="I have a number between 1 and 100. Guess it!",\n)\n'})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"agent_with_number (to agent_guess_number):\n\nI have a number between 1 and 100. Guess it!\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\n50\n\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\n\nToo low.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\n75\n\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\n\nToo high.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\n62\n\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\n\nToo high.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\n56\n\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\n\nToo high.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\n53\n\n--------------------------------------------------------------------------------\n"})}),"\n",(0,o.jsx)(e.p,{children:"Yay! The game is over. The guessing agent got the number correctly in\nexactly 5 guesses using binary search \u2013 very efficient! You can see that\nthe conversation was terminated after the 5th guess which triggered both\nthe counter-based and message-based termination conditions."}),"\n",(0,o.jsxs)(e.h2,{id:"human-input-mode-always",children:["Human Input Mode = ",(0,o.jsx)(e.code,{children:"ALWAYS"})]}),"\n",(0,o.jsx)(e.p,{children:"In this mode, human input is always requested and the human can choose\nto skip, intersecpt, or terminate the conversation. Let us see this mode\nin action by playing the same game as before with the agent with the\nnumber, but this time participating in the game as a human. We will be\nthe agent that is guessing the number, and play against the agent with\nthe number from before."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'human_proxy = ConversableAgent(\n    "human_proxy",\n    llm_config=False,  # no LLM used for human proxy\n    human_input_mode="ALWAYS",  # always ask for human input\n)\n\n# Start a chat with the agent with number with an initial guess.\nresult = human_proxy.initiate_chat(\n    agent_with_number,  # this is the same agent with the number as before\n    message="10",\n)\n'})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"human_proxy (to agent_with_number):\n\n10\n\n--------------------------------------------------------------------------------\nagent_with_number (to human_proxy):\n\nToo low.\n\n--------------------------------------------------------------------------------\nhuman_proxy (to agent_with_number):\n\n70\n\n--------------------------------------------------------------------------------\nagent_with_number (to human_proxy):\n\nToo high.\n\n--------------------------------------------------------------------------------\nhuman_proxy (to agent_with_number):\n\n50\n\n--------------------------------------------------------------------------------\nagent_with_number (to human_proxy):\n\nToo low.\n\n--------------------------------------------------------------------------------\nhuman_proxy (to agent_with_number):\n\n53\n\n--------------------------------------------------------------------------------\n"})}),"\n",(0,o.jsx)(e.p,{children:"If you run the code above, you will be prompt to enter a response each\ntime it is your turn to speak. You can see the human in the conversation\nwas not very good at guessing the number\u2026 but hey the agent was nice\nenough to give out the number in the end."}),"\n",(0,o.jsxs)(e.h2,{id:"human-input-mode-terminate",children:["Human Input Mode = ",(0,o.jsx)(e.code,{children:"TERMINATE"})]}),"\n",(0,o.jsxs)(e.p,{children:["In this mode, human input is only requested when a termination condition\nis met. ",(0,o.jsx)(e.strong,{children:"If the human choose to intercept and reply, the counter will\nbe reset"}),"; if the human choose to skip, automatic reply mechanism will\nbe used; if the human choose to terminate, the conversation will be\nterminated."]}),"\n",(0,o.jsx)(e.p,{children:"Let us see this mode in action by playing the same game again, but this\ntime the agent with the number will choose a new number and the game\nwill restart."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'agent_with_number = ConversableAgent(\n    "agent_with_number",\n    system_message="You are playing a game of guess-my-number. "\n    "In the first game, you have the "\n    "number 53 in your mind, and I will try to guess it. "\n    "If I guess too high, say \'too high\', if I guess too low, say \'too low\'. ",\n    llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},\n    max_consecutive_auto_reply=5,\n    human_input_mode="TERMINATE",  # ask for human input until the game is terminated\n)\n\nagent_guess_number = ConversableAgent(\n    "agent_guess_number",\n    system_message="I have a number in my mind, and you will try to guess it. "\n    "If I say \'too high\', you should guess a lower number. If I say \'too low\', "\n    "you should guess a higher number. ",\n    llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},\n    human_input_mode="NEVER",\n)\n\nresult = agent_with_number.initiate_chat(\n    agent_guess_number,\n    message="I have a number between 1 and 100. Guess it!",\n)\n'})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"agent_with_number (to agent_guess_number):\n\nI have a number between 1 and 100. Guess it!\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\n50\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nToo low.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\n75\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nToo high.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\n62\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nToo high.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\n56\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nToo high.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\n53\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nCorrect! You've guessed my number.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nGreat! This was a fun game. Let's play again sometime.\n\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\n\n10\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nYour guess is too high.\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nOkay, let's try 5.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nYour guess is too high.\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nOkay, how about 2?\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nYour guess is too low.\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nAlright, then it must be 3.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nYes, correct! The number was 3. Good job guessing it!\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nThank you! That was indeed a fun game. I look forward to playing again with you.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nI'm glad you enjoyed it! I'm always here for a good game. Don't hesitate to come back when you want to play again.\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nSurely, I will. This was fun. Thanks for playing with me. See you next time!\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nYou're welcome! I'm glad you had fun. Looking forward to our next game. See you next time!\n\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\n\nLets play again\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nSure! I'll think of a number between 1 and 100. Let's start guessing!\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nI'll start with 50.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nThe guess is too low.\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nOkay, let's try 75.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nThe guess is too high.\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nHow about 62?\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nThe guess is too low.\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nThen, let's try 68.\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nThe guess is too high.\n\n--------------------------------------------------------------------------------\n\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\n\nOkay, how about 65?\n\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\n\nYes, correct! The number was 65. Good job guessing it!\n\n--------------------------------------------------------------------------------\n"})}),"\n",(0,o.jsx)(e.p,{children:"In the previous conversation, we were asked to provide human input first\ntime when the counter-based termination condition was met. We\nintercepted the message and replied \u201cLet\u2019s play again\u201d. The conversation\ncontinued and the counter was reset. The game continued until the\ncounter-based termination condition was met again, and this time we\nchose to skip. The conversation continued again but human input was\nrequested at every turn since, and we chose to skip each time until the\ngame was over."}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"In this chapter, we showed you how to use the human-in-the-loop\ncomponent to provide human feedback to agent and to terminate\nconversation. We also showed you the different human input modes and how\nthey affect the behavior of the human-in-the-loop component."}),"\n",(0,o.jsx)(e.p,{children:"The next chapter will be all about code executor \u2013 the most powerful\ncomponent second only to LLMs."})]})}function g(n={}){const{wrapper:e}={...(0,a.a)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(m,{...n})}):m(n)}},11151:(n,e,t)=>{t.d(e,{Z:()=>u,a:()=>i});var o=t(67294);const a={},s=o.createContext(a);function i(n){const e=o.useContext(s);return o.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function u(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:i(n.components),o.createElement(s.Provider,{value:e},n.children)}}}]);